{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import torch as th\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch as th\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "BASE_DIR = Path(\"..\")\n",
    "\n",
    "CHECKPOINT_DIR = BASE_DIR / \"checkpoints\" / \"feature_scaler\"\n",
    "PLOTS_DIR = BASE_DIR / \"plots\"\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_init_names = [\"S4-L13-mu0.0e+00-lr1e-02\", \"S42-L13-mu0.0e+00-lr1e-02\", \"S666-L13-mu0.0e+00-lr1e-02\"]\n",
    "zero_init_names = [\"S4-L13-mu0.0e+00-lr1e-02-ZeroInit\", \"S42-L13-mu0.0e+00-lr1e-02-ZeroInit\", \"S666-L13-mu0.0e+00-lr1e-02-ZeroInit\"]\n",
    "\n",
    "random_indices_names = [\"RandomIndicesL13-mu0.0e+00-lr1e-02\", \"RandomIndicesS4-L13-mu0.0e+00-lr1e-02\", \"RandomIndicesS666-L13-mu0.0e+00-lr1e-02\"]\n",
    "random_sources_names = [\"RandomSourceL13-mu0.0e+00-lr1e-02\", \"RandomSourceS4-L13-mu0.0e+00-lr1e-02\", \"RandomSourceS666-L13-mu0.0e+00-lr1e-02\"]\n",
    "full_scaler_name = \"L13-mu0.0e+00-lr1e-02-full\"\n",
    "\n",
    "base_model_fve = 0.83579\n",
    "\n",
    "def load_fve(name):\n",
    "    with open(CHECKPOINT_DIR / name / \"last_eval_logs.json\", \"r\") as f:\n",
    "        return json.load(f)[\"val/frac_variance_explained\"]\n",
    "one_init_fve = [load_fve(name) for name in one_init_names]\n",
    "zero_init_fve = [load_fve(name) for name in zero_init_names]\n",
    "random_indices_fve = [load_fve(name) for name in random_indices_names]\n",
    "random_sources_fve = [load_fve(name) for name in random_sources_names]\n",
    "full_scaler_fve = load_fve(full_scaler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot with std for one_init\n",
    "one_init_fve_mean = np.mean(one_init_fve)\n",
    "one_init_fve_std = np.std(one_init_fve)\n",
    "zero_init_fve_mean = np.mean(zero_init_fve)\n",
    "zero_init_fve_std = np.std(zero_init_fve)\n",
    "random_indices_fve_mean = np.mean(random_indices_fve)\n",
    "random_indices_fve_std = np.std(random_indices_fve)\n",
    "random_sources_fve_mean = np.mean(random_sources_fve)\n",
    "random_sources_fve_std = np.std(random_sources_fve)\n",
    "\n",
    "# Calculate relative improvements\n",
    "rel_one_init = (one_init_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_zero_init = (zero_init_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_random_indices = (random_indices_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_random_sources = (random_sources_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_full_scaler = (full_scaler_fve - base_model_fve) / base_model_fve * 100\n",
    "\n",
    "# Convert std to relative\n",
    "rel_one_init_std = one_init_fve_std / base_model_fve * 100\n",
    "rel_zero_init_std = zero_init_fve_std / base_model_fve * 100\n",
    "rel_random_indices_std = random_indices_fve_std / base_model_fve * 100\n",
    "rel_random_sources_std = random_sources_fve_std / base_model_fve * 100\n",
    "\n",
    "fig = px.bar(\n",
    "    x=[\"S_I 1-init\", \"S_I Zero Init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"],\n",
    "    y=[rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources],\n",
    "    title=\"Relative FVE Improvement Over CrossCoder (%)\",\n",
    "    error_y=[rel_one_init_std, rel_zero_init_std, rel_random_indices_std, rel_random_sources_std],\n",
    ")\n",
    "\n",
    "# horizontal dashed blue line at full scaler improvement\n",
    "fig.add_hline(y=rel_full_scaler, line_dash=\"dash\", line_color=\"blue\")\n",
    "fig.update_traces(texttemplate='%{y:.2f}%', textposition='auto')\n",
    "\n",
    "# add annotation for full scaler line\n",
    "fig.add_annotation(\n",
    "    x=2,\n",
    "    y=rel_full_scaler,\n",
    "    text=\"Full Scaler Improvement\",\n",
    "    font=dict(size=16, color=\"blue\")\n",
    ")\n",
    "# Add scatter points for individual runs\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['S_I 1-init'] * len(one_init_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in one_init_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['S_I Zero Init'] * len(zero_init_fve), \n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in zero_init_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['Random Set <br> 1-init'] * len(random_indices_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in random_indices_fve],\n",
    "    mode='markers', \n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['Random Vectors <br> 1-init'] * len(random_sources_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in random_sources_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# text annotations\n",
    "# font size of 20\n",
    "fig.update_layout(font=dict(size=20), width=800, height=600)\n",
    "# axis labels\n",
    "fig.update_yaxes(title=\"Relative FVE Improvement (%)\", title_font_size=20)\n",
    "# remove x axis title\n",
    "fig.update_xaxes(title=\"\", title_font_size=20)\n",
    "min_y = min(rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources, rel_full_scaler)\n",
    "max_y = max(rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources, rel_full_scaler)\n",
    "fig.update_layout(yaxis_range=[min_y-0.1, max_y+0.1])\n",
    "fig.show()\n",
    "fig.write_image(PLOTS_DIR / \"scaler_fve_improvement.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_func(x):\n",
    "    return th.nn.functional.elu(x) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_init_scalers = []\n",
    "for name in one_init_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    one_init_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "one_init_scalers = np.stack(one_init_scalers)\n",
    "\n",
    "# Load all zero init scalers \n",
    "zero_init_scalers = []\n",
    "for name in zero_init_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    zero_init_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "zero_init_scalers = np.stack(zero_init_scalers)\n",
    "\n",
    "# Load Random Indices and Random Sources scalers\n",
    "random_indices_scalers = []\n",
    "for name in random_indices_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    random_indices_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "random_indices_scalers = np.stack(random_indices_scalers)\n",
    "\n",
    "random_sources_scalers = []\n",
    "for name in random_sources_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    random_sources_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "random_sources_scalers = np.stack(random_sources_scalers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all one init scalers\n",
    "threshold = 5e-2\n",
    "\n",
    "thres_one_init = (one_init_scalers < threshold).mean(axis=1)\n",
    "thres_zero_init = (zero_init_scalers < threshold).mean(axis=1)\n",
    "thres_random_indices = (random_indices_scalers < threshold).mean(axis=1)\n",
    "thres_random_sources = (random_sources_scalers < threshold).mean(axis=1)\n",
    "\n",
    "\n",
    "one_init_mean = thres_one_init.mean() * 100\n",
    "zero_init_mean = thres_zero_init.mean() * 100\n",
    "random_indices_mean = thres_random_indices.mean() * 100\n",
    "random_sources_mean = thres_random_sources.mean() * 100\n",
    "\n",
    "one_init_std = thres_one_init.std() * 100\n",
    "zero_init_std = thres_zero_init.std() * 100\n",
    "random_indices_std = thres_random_indices.std() * 100\n",
    "random_sources_std = thres_random_sources.std() * 100\n",
    "\n",
    "# Create bar plot\n",
    "fig = px.bar(\n",
    "    x=[\"S_I 1-init\", \"S_I 0-init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"],\n",
    "    y=[one_init_mean, zero_init_mean, random_indices_mean, random_sources_mean],\n",
    "    error_y=[one_init_std, zero_init_std, random_indices_std, random_sources_std],\n",
    "    title=f\"Percentage of Dead Feature Scalars (beta_i < {threshold:.1})\",\n",
    ")\n",
    "\n",
    "# Add text annotations\n",
    "fig.update_traces(texttemplate='%{y:.1f}%', textposition='auto')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    font=dict(size=20),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    yaxis_title=\"Percentage of Dead Scalars\",\n",
    "    xaxis_title=\"\"\n",
    ")\n",
    "\n",
    "# Add min/max annotations for each bar\n",
    "y_positions = [one_init_mean, zero_init_mean, random_indices_mean, random_sources_mean]\n",
    "stds = [one_init_std, zero_init_std, random_indices_std, random_sources_std]\n",
    "x_positions = [\"1-init\", \"0-init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"]\n",
    "\n",
    "\n",
    "# Set y-axis range from 0 to slightly above max\n",
    "max_y = max(one_init_mean + one_init_std, \n",
    "            zero_init_mean + zero_init_std,\n",
    "            random_indices_mean + random_indices_std,\n",
    "            random_sources_mean + random_sources_std)\n",
    "fig.update_layout(yaxis_range=[0, max_y * 1.1])\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(PLOTS_DIR / \"scaler_dead_scalars.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "# Create subplots in a 2x3 grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=[\n",
    "        # First row: One init seed comparisons\n",
    "        f'1-init Seeds {i+1} vs {j+1}' \n",
    "        for i in range(3) \n",
    "        for j in range(i+1,3)\n",
    "    ] + [\n",
    "        # First row: One init seed comparisons\n",
    "        f'1-init Seed {i+1} vs 0-init Seed {j+1}' \n",
    "        for i in range(3) \n",
    "        for j in range(i+1,3)\n",
    "    ],\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# First row: One init seed comparisons\n",
    "pairs = [(i,j) for i in range(3) for j in range(i+1,3)]\n",
    "for idx, (i,j) in enumerate(pairs):\n",
    "    # Create 2D histogram data for this pair\n",
    "    x = np.array(one_init_scalers[i]).flatten() # Ensure 1D array\n",
    "    y = np.array(one_init_scalers[j]).flatten() # Ensure 1D array\n",
    "    hist2d, x_edges, y_edges = np.histogram2d(\n",
    "        x,\n",
    "        y,\n",
    "        bins=30\n",
    "    )\n",
    "    \n",
    "    # Add heatmap to subplot\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_edges[:-1],\n",
    "            y=y_edges[:-1], \n",
    "            z=np.log1p(hist2d.T),\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='Log Count'),\n",
    "            showscale=(idx==2) # only show colorbar for rightmost plot\n",
    "        ),\n",
    "        row=1, col=idx+1\n",
    "    )\n",
    "\n",
    "# Second row: One init vs Two init comparisons\n",
    "for idx, (i,j) in enumerate(pairs):\n",
    "    x = np.array(one_init_scalers[i]).flatten()\n",
    "    y = np.array(zero_init_scalers[j]).flatten()\n",
    "    hist2d, x_edges, y_edges = np.histogram2d(\n",
    "        x,\n",
    "        y,\n",
    "        bins=30\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_edges[:-1],\n",
    "            y=y_edges[:-1], \n",
    "            z=np.log1p(hist2d.T),\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='Log Count'),\n",
    "            showscale=(idx==2) # only show colorbar for rightmost plot\n",
    "        ),\n",
    "        row=2, col=idx+1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='<b>Are the same features \"dying\"?</b> <br>2D Distributions of Feature Scaling Values',\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.write_image(PLOTS_DIR / \"scaler_2d_histo.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute refined feature indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.feature_utils import mask_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-4).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-4.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-3).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-3.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-2).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()\n",
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-2.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=scaled_values_one,\n",
    "            y=scaled_values_zero,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"blue\", opacity=0.5),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Scatter Plot of Feature Scaling Values\",\n",
    "    xaxis_title=\"One Init Scaling Factor\",\n",
    "    yaxis_title=\"Zero Init Scaling Factor\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_dashboard import OfflineFeatureCentricDashboard\n",
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>dead</th>\n",
       "      <th>dec_norm_diff</th>\n",
       "      <th>base uselessness score</th>\n",
       "      <th>avg_activation</th>\n",
       "      <th>lmsys_ctrl_%</th>\n",
       "      <th>lmsys_bos_%</th>\n",
       "      <th>lmsys_user_%</th>\n",
       "      <th>lmsys_assistant_%</th>\n",
       "      <th>lmsys_dead</th>\n",
       "      <th>...</th>\n",
       "      <th>lmsys_ctrl_2_%</th>\n",
       "      <th>lmsys_ctrl_3_%</th>\n",
       "      <th>lmsys_ctrl_4_%</th>\n",
       "      <th>lmsys_ctrl_5_%</th>\n",
       "      <th>lmsys_ctrl_6_%</th>\n",
       "      <th>lmsys_ctrl_7_%</th>\n",
       "      <th>lmsys_ctrl_8_%</th>\n",
       "      <th>lmsys_ctrl_9_%</th>\n",
       "      <th>lmsys_ctrl_10_%</th>\n",
       "      <th>bos_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>0.352013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.492434</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474680</td>\n",
       "      <td>0.525320</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>0.363011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.259659</td>\n",
       "      <td>0.059572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.955339</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017415</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.128323</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>0.014665</td>\n",
       "      <td>0.368469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.845021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507097</td>\n",
       "      <td>0.492903</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.456325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.206497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164352</td>\n",
       "      <td>0.835648</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.518658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459546</td>\n",
       "      <td>0.540454</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73723</th>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>0.391009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.952224</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148037</td>\n",
       "      <td>0.851963</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73724</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.452103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.380469</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275816</td>\n",
       "      <td>0.724184</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73725</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.456605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.164577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221741</td>\n",
       "      <td>0.778259</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73726</th>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.219504</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201370</td>\n",
       "      <td>0.798630</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73727</th>\n",
       "      <td>Shared</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.019318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488814</td>\n",
       "      <td>0.511186</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73728 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tag   dead  dec_norm_diff  base uselessness score  avg_activation  \\\n",
       "feature                                                                         \n",
       "0         Other  False       0.352013                     NaN        3.492434   \n",
       "1         Other  False       0.363011                     NaN       15.259659   \n",
       "2        Shared  False       0.484854                     NaN       15.845021   \n",
       "3        Shared  False       0.456325                     NaN        9.206497   \n",
       "4        Shared  False       0.518658                     NaN       12.409294   \n",
       "...         ...    ...            ...                     ...             ...   \n",
       "73723     Other  False       0.391009                     NaN        6.952224   \n",
       "73724    Shared  False       0.452103                     NaN        5.380469   \n",
       "73725    Shared  False       0.456605                     NaN       43.164577   \n",
       "73726     Other  False       0.388642                     NaN        8.219504   \n",
       "73727    Shared  False       0.430915                     NaN       17.019318   \n",
       "\n",
       "         lmsys_ctrl_%  lmsys_bos_%  lmsys_user_%  lmsys_assistant_%  \\\n",
       "feature                                                               \n",
       "0            0.000212          0.0      0.474680           0.525320   \n",
       "1            0.059572          0.0      0.044661           0.955339   \n",
       "2            0.000000          0.0      0.507097           0.492903   \n",
       "3            0.000000          0.0      0.164352           0.835648   \n",
       "4            0.002478          0.0      0.459546           0.540454   \n",
       "...               ...          ...           ...                ...   \n",
       "73723        0.002608          0.0      0.148037           0.851963   \n",
       "73724        0.000303          0.0      0.275816           0.724184   \n",
       "73725        0.000000          0.0      0.221741           0.778259   \n",
       "73726        0.003323          0.0      0.201370           0.798630   \n",
       "73727        0.000000          0.0      0.488814           0.511186   \n",
       "\n",
       "         lmsys_dead  ...  lmsys_ctrl_2_%  lmsys_ctrl_3_%  lmsys_ctrl_4_%  \\\n",
       "feature              ...                                                   \n",
       "0             False  ...        0.000000        0.000000        0.000000   \n",
       "1             False  ...        0.000000        0.017415        0.004583   \n",
       "2             False  ...             NaN             NaN             NaN   \n",
       "3             False  ...             NaN             NaN             NaN   \n",
       "4             False  ...        0.000000        0.000000        0.428571   \n",
       "...             ...  ...             ...             ...             ...   \n",
       "73723         False  ...        0.003571        0.050000        0.100000   \n",
       "73724         False  ...        0.000000        0.000000        0.000000   \n",
       "73725         False  ...             NaN             NaN             NaN   \n",
       "73726         False  ...        0.000000        0.032967        0.010989   \n",
       "73727         False  ...             NaN             NaN             NaN   \n",
       "\n",
       "         lmsys_ctrl_5_%  lmsys_ctrl_6_%  lmsys_ctrl_7_%  lmsys_ctrl_8_%  \\\n",
       "feature                                                                   \n",
       "0              0.000000        0.000000        1.000000        0.000000   \n",
       "1              0.128323        0.024748        0.002750        0.433547   \n",
       "2                   NaN             NaN             NaN             NaN   \n",
       "3                   NaN             NaN             NaN             NaN   \n",
       "4              0.428571        0.000000        0.000000        0.000000   \n",
       "...                 ...             ...             ...             ...   \n",
       "73723          0.300000        0.000000        0.078571        0.135714   \n",
       "73724          1.000000        0.000000        0.000000        0.000000   \n",
       "73725               NaN             NaN             NaN             NaN   \n",
       "73726          0.703297        0.010989        0.000000        0.021978   \n",
       "73727               NaN             NaN             NaN             NaN   \n",
       "\n",
       "         lmsys_ctrl_9_%  lmsys_ctrl_10_%  bos_%  \n",
       "feature                                          \n",
       "0              0.000000         0.000000    0.0  \n",
       "1              0.014665         0.368469    0.0  \n",
       "2                   NaN              NaN    0.0  \n",
       "3                   NaN              NaN    0.0  \n",
       "4              0.000000         0.142857    0.0  \n",
       "...                 ...              ...    ...  \n",
       "73723          0.010714         0.321429    0.0  \n",
       "73724          0.000000         0.000000    0.0  \n",
       "73725               NaN              NaN    0.0  \n",
       "73726          0.000000         0.219780    0.0  \n",
       "73727               NaN              NaN    0.0  \n",
       "\n",
       "[73728 rows x 96 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id = \"Butanium/max-activating-examples-gemma-2-2b-l13-mu4.1e-02-lr1e-04\"\n",
    "\n",
    "df_path = hf_hub_download(repo_id=repo_id, filename=\"feature_df.csv\", repo_type=\"dataset\")\n",
    "df = pd.read_csv(df_path, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scalars(path, indices_path=\"/workspace/data/only_it_decoder_feature_indices.pt\"):\n",
    "    act_func = lambda x: th.nn.functional.elu(x) + 1\n",
    "    scalers = th.load(path)[\"scaler\"]\n",
    "    feature_indices = th.load(indices_path)\n",
    "    return act_func(scalers).cpu().numpy(), feature_indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91446/4374123.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  scalers = th.load(path)[\"scaler\"]\n",
      "/tmp/ipykernel_91446/4374123.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  feature_indices = th.load(indices_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3176,), (3176,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CKPT_PATH = \"/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/checkpoint_95000.pt\"\n",
    "individual_scalers, feature_indices = load_scalars(CKPT_PATH)\n",
    "joint_base_uselessness_score = df[\"base uselessness score\"].iloc[feature_indices]\n",
    "individual_base_uselessness_score = -np.log(individual_scalers + 1e-10)\n",
    "joint_scalers = np.exp(-joint_base_uselessness_score.to_numpy() + 1e-10)\n",
    "individual_scalers.shape, feature_indices.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX INDIVIDUAL SCALER\n",
      "______________________\n",
      "Value:  50.871265\n",
      "Index:  54708\n",
      "Joint Value:  1.0000000001\n",
      "Dead:  True\n",
      "lmsys_freq                0.0\n",
      "fw_freq                   0.0\n",
      "dec_base_norm        0.003525\n",
      "dec_instruct_norm    0.037675\n",
      "Name: 54708, dtype: object\n",
      "\n",
      "\n",
      "MAX JOINT SCALER\n",
      "______________________\n",
      "Value:  1.3752346176052348\n",
      "Index:  21153\n",
      "Individual Value:  0.0\n",
      "Dead:  False\n",
      "lmsys_freq           0.001295\n",
      "fw_freq               0.00579\n",
      "dec_base_norm        0.078196\n",
      "dec_instruct_norm    0.563799\n",
      "Name: 21153, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX INDIVIDUAL SCALER\\n______________________\")\n",
    "print(\"Value: \", individual_scalers.max())\n",
    "print(\"Index: \", feature_indices[np.argmax(individual_scalers)])\n",
    "print(\"Joint Value: \", joint_scalers[np.argmax(individual_scalers)])\n",
    "print(\"Dead: \", df.iloc[feature_indices[np.argmax(individual_scalers)]][\"dead\"])\n",
    "print(df.iloc[feature_indices[np.argmax(individual_scalers)]][[\"lmsys_freq\", \"fw_freq\", \"dec_base_norm\", \"dec_instruct_norm\"]])\n",
    "print(\"\\n\\nMAX JOINT SCALER\\n______________________\")\n",
    "print(\"Value: \", joint_scalers.max())\n",
    "print(\"Index: \", feature_indices[np.argmax(joint_scalers)])\n",
    "print(\"Individual Value: \", individual_scalers[np.argmax(joint_scalers)])\n",
    "print(\"Dead: \", df.iloc[feature_indices[np.argmax(joint_scalers)]][\"dead\"])\n",
    "print(df.iloc[feature_indices[np.argmax(joint_scalers)]][[\"lmsys_freq\", \"fw_freq\", \"dec_base_norm\", \"dec_instruct_norm\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_mask = (~df[\"dead\"])[feature_indices].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot joint and individual scalers\n",
    "# Create common bins for both histograms\n",
    "remove_dead = True\n",
    "if remove_dead:\n",
    "    joint_scalers_local = joint_scalers[dead_mask]\n",
    "    individual_scalers_local = individual_scalers[dead_mask]\n",
    "all_values = np.concatenate([joint_scalers_local, individual_scalers_local])\n",
    "bins = np.histogram_bin_edges(all_values, bins=50)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=joint_scalers_local,\n",
    "    name='Joint Scalers',\n",
    "    opacity=0.75,\n",
    "    xbins=dict(\n",
    "        start=bins[0],\n",
    "        end=bins[-1],\n",
    "        size=(bins[1]-bins[0])\n",
    "    ),\n",
    "    nbinsx=50\n",
    "))\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=individual_scalers_local,\n",
    "    name='Individual Scalers',\n",
    "    opacity=0.75,\n",
    "    xbins=dict(\n",
    "        start=bins[0],\n",
    "        end=bins[-1],\n",
    "        size=(bins[1]-bins[0])\n",
    "    ),\n",
    "    nbinsx=50\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='Distribution of Joint vs Individual Scalers',\n",
    "    xaxis_title='Scaler Value',\n",
    "    yaxis_title='Count',\n",
    "    yaxis_type='log',\n",
    "    barmode='group',\n",
    "    width=500,\n",
    "    height=500\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"right\",\n",
    "        x=0.99\n",
    "    )\n",
    ")\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=40, b=20))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = df[\"freq\"].iloc[feature_indices][dead_mask]\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(frequency, joint_scalers[dead_mask], alpha=0.5)\n",
    "plt.xlabel('Feature Frequency')\n",
    "plt.ylabel('Joint Scaler Value')\n",
    "plt.title('Feature Frequency vs Joint Scaler Values')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = df[\"freq\"].iloc[feature_indices][dead_mask]\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(frequency, individual_scalers[dead_mask], alpha=0.5)\n",
    "plt.xlabel('Feature Frequency')\n",
    "plt.ylabel('Individual Scaler Value')\n",
    "plt.title('Feature Frequency vs Individual Scaler Values')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# Create 2D histogram\n",
    "plt.hist2d(joint_scalers, individual_scalers, bins=30, cmap='viridis', norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(label='Count')\n",
    "\n",
    "plt.title(\"Joint Distribution of Scalar Values\")\n",
    "plt.xlabel(\"Joint Scalar Value\") \n",
    "plt.ylabel(\"Individual Scaler Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# Create 2D histogram\n",
    "plt.hist2d(joint_base_uselessness_score, individual_base_uselessness_score, bins=30, cmap='viridis', norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(label='Count')\n",
    "\n",
    "plt.title(\"Joint Distribution of Base Uselessness Scores\")\n",
    "plt.xlabel(\"Joint Base Uselessness Score\") \n",
    "plt.ylabel(\"Individual Base Uselessness Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_0.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_100.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_10000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_200.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_20000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_30000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_40000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_50000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_60000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_70000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_80000.pt'),\n",
       " PosixPath('/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents/eval_logs_90000.pt')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"/workspace/data/checkpoints/feature_scaler/L13-mu0.0e+00-lr5e-04-s42-Individual-alllatents\")\n",
    "files = list(base_path.glob(\"eval_logs*\"))\n",
    "files = sorted(files)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91446/3392004205.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  validation_data = [th.load(f) for f in files]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['val/frac_deads', 'val/l0', 'val/frac_variance_explained', 'val/frac_variance_explained_per_feature', 'step'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = [th.load(f) for f in files]\n",
    "validation_data[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1281)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[0][\"val/frac_variance_explained\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0673)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.tensor(validation_data[-1][\"val/frac_variance_explained_per_feature\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract steps and variance explained values\n",
    "steps = [data[\"step\"] for data in validation_data]\n",
    "variance_explained = [data[\"val/frac_variance_explained\"] for data in validation_data]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, variance_explained, marker='o')\n",
    "\n",
    "plt.title(\"Fraction of Variance Explained vs Training Steps\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Fraction of Variance Explained\")\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
